{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705dfa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4144d",
   "metadata": {},
   "source": [
    "### Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "170309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_all = np.load(\"npy/face_all.npy\", allow_pickle = True)\n",
    "nirs_all= np.load(\"npy/nirs_all.npy\", allow_pickle = True)\n",
    "clip_idx = np.load(\"npy/clip_idx.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039003eb",
   "metadata": {},
   "source": [
    "## S2S-RNN-Autoencoder (Unimodal Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d59f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2787373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(S2SAutoencoder, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, input_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out, (hidden, cell) = self.encoder(x)\n",
    "        encoder_last_timestep = encoder_out[:, -1, :] # Get the LSTM output at the last time step\n",
    "        decoder_out, _ = self.decoder(encoder_out, (hidden, cell))\n",
    "        \n",
    "        return decoder_out, encoder_last_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "680d6063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1552486359750675\n",
      "Epoch [2/20], Loss: 0.10694790485745204\n",
      "Epoch [3/20], Loss: 0.10246796314784186\n",
      "Epoch [4/20], Loss: 0.10080909536606505\n",
      "Epoch [5/20], Loss: 0.10003180716008032\n",
      "Epoch [6/20], Loss: 0.09956258511904939\n",
      "Epoch [7/20], Loss: 0.09922375103155623\n",
      "Epoch [8/20], Loss: 0.09897980302123674\n",
      "Epoch [9/20], Loss: 0.09879538746286089\n",
      "Epoch [10/20], Loss: 0.09861416492684764\n",
      "Epoch [11/20], Loss: 0.09845144467766512\n",
      "Epoch [12/20], Loss: 0.0983365008560196\n",
      "Epoch [13/20], Loss: 0.09826319518578804\n",
      "Epoch [14/20], Loss: 0.09816904080749567\n",
      "Epoch [15/20], Loss: 0.09814021623538333\n",
      "Epoch [16/20], Loss: 0.09806938392310802\n",
      "Epoch [17/20], Loss: 0.09807119976907884\n",
      "Epoch [18/20], Loss: 0.09802876245353094\n",
      "Epoch [19/20], Loss: 0.09799605605883746\n",
      "Epoch [20/20], Loss: 0.09795771288288616\n",
      "embeddings_dim35.csv saved!\n",
      "Epoch [1/20], Loss: 0.3670540795445106\n",
      "Epoch [2/20], Loss: 0.18490833247313496\n",
      "Epoch [3/20], Loss: 0.16829946970782633\n",
      "Epoch [4/20], Loss: 0.16200265637401803\n",
      "Epoch [5/20], Loss: 0.15857144779510804\n",
      "Epoch [6/20], Loss: 0.15642841752558975\n",
      "Epoch [7/20], Loss: 0.15497430573066\n",
      "Epoch [8/20], Loss: 0.15395567717551065\n",
      "Epoch [9/20], Loss: 0.15318151802413327\n",
      "Epoch [10/20], Loss: 0.15261265388072265\n",
      "Epoch [11/20], Loss: 0.1521920283182208\n",
      "Epoch [12/20], Loss: 0.1518486535434216\n",
      "Epoch [13/20], Loss: 0.15155358957380813\n",
      "Epoch [14/20], Loss: 0.15135245531208652\n",
      "Epoch [15/20], Loss: 0.15115490414181187\n",
      "Epoch [16/20], Loss: 0.15099761675016452\n",
      "Epoch [17/20], Loss: 0.15087203921878103\n",
      "Epoch [18/20], Loss: 0.15074483199379743\n",
      "Epoch [19/20], Loss: 0.15066043002949722\n",
      "Epoch [20/20], Loss: 0.1505590423394909\n",
      "embeddings_dim40.csv saved!\n"
     ]
    }
   ],
   "source": [
    "face_reshaped = face_all\n",
    "nirs_reshaped = nirs_all\n",
    "\n",
    "for reshaped in [face_reshaped,nirs_reshaped]:\n",
    "    unimodal_autoencoder = S2SAutoencoder(reshaped.shape[2], reshaped.shape[2]).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(unimodal_autoencoder.parameters(), lr=0.001)\n",
    "    batch_size = 128\n",
    "\n",
    "    uni_tensor = torch.from_numpy(reshaped).float().to(device)\n",
    "    label_tensor = torch.tensor(clip_idx).to(device)\n",
    "    train_dataset = TensorDataset(uni_tensor, label_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "\n",
    "    num_epochs = 20\n",
    "    all_bottlenecks = []\n",
    "    ys = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_data, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs, bottleneck = unimodal_autoencoder(batch_data)\n",
    "            loss = criterion(outputs, batch_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # Append the bottleneck embeddings to the list\n",
    "            if epoch == num_epochs - 1:\n",
    "                all_bottlenecks.append(bottleneck)\n",
    "                ys.append(y)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}')\n",
    "        \n",
    "    torch.save(unimodal_autoencoder.state_dict(), 'models/feature_selection/unimodal_autoencoder.pth')\n",
    "    all_bottlenecks_combined = torch.cat(all_bottlenecks, dim=0)\n",
    "    ys = torch.cat(ys, dim=0)\n",
    "    \n",
    "    cluster_idx = []\n",
    "    subject_label = []\n",
    "    for y in ys:\n",
    "        cluster_idx.append(int(str(y.item())[:-4]+str(0)))\n",
    "        subject_label.append((int(str(y.item())[:-3])))\n",
    "    \n",
    "    embeddings = all_bottlenecks_combined.cpu()\n",
    "    embeddings_np = embeddings.detach().numpy()\n",
    "    \n",
    "    unimodal_df = pd.DataFrame(data=embeddings_np, columns=[f\"dim_{i+1}\" for i in range(embeddings_np.shape[1])])\n",
    "    unimodal_df['idx'] = ys.cpu()\n",
    "    unimodal_df['cluster_idx'] = cluster_idx\n",
    "    unimodal_df['subject_idx'] = subject_label\n",
    "    unimodal_df['t'] = unimodal_df['idx'].apply(lambda x: str(x)[-3:])\n",
    "\n",
    "    unimodal_df = unimodal_df.sort_values(by=['subject_idx', 't'])\n",
    "    unimodal_df = unimodal_df.reset_index(drop=True)\n",
    "    unimodal_df.to_csv('output/feature_selection/unimodal_embeddings_dim'+str(reshaped.shape[2])+'.csv')\n",
    "    \n",
    "    print('unimodal_embeddings_dim'+str(reshaped.shape[2])+'.csv saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994a8bf",
   "metadata": {},
   "source": [
    "## FCN-Autoencoder (Multimodal Integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cab5b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df=pd.read_csv('output/feature_selection/unimodal_embeddings_dim35.csv')\n",
    "fnirs_df=pd.read_csv('output/feature_selection/unimodal_embeddings_dim40.csv')\n",
    "\n",
    "multimodal = pd.concat([fnirs_df.iloc[:, 1:-4], face_df.iloc[:, 1:-4]], axis = 1)\n",
    "multimodal_all = multimodal.values\n",
    "multimodal_idx = fnirs_df['idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3b899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(75, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 75),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafe7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.05494650969542878\n",
      "Epoch [2/20], Loss: 0.035834317366300834\n",
      "Epoch [3/20], Loss: 0.03289301559567339\n",
      "Epoch [4/20], Loss: 0.03218977303819789\n",
      "Epoch [5/20], Loss: 0.03209191805710236\n",
      "Epoch [6/20], Loss: 0.0320796100291321\n",
      "Epoch [7/20], Loss: 0.032078312846603306\n",
      "Epoch [8/20], Loss: 0.03207520301246127\n",
      "Epoch [9/20], Loss: 0.03207374452801661\n",
      "Epoch [10/20], Loss: 0.03207119166858053\n",
      "Epoch [11/20], Loss: 0.032068715026901784\n",
      "Epoch [12/20], Loss: 0.03206831160214355\n",
      "Epoch [13/20], Loss: 0.03206578362470288\n",
      "Epoch [14/20], Loss: 0.032064745819453684\n",
      "Epoch [15/20], Loss: 0.032063153802801836\n",
      "Epoch [16/20], Loss: 0.032059678576557234\n",
      "Epoch [17/20], Loss: 0.03205494557070149\n",
      "Epoch [18/20], Loss: 0.03204210499618711\n",
      "Epoch [19/20], Loss: 0.03202885965293629\n",
      "Epoch [20/20], Loss: 0.03202324041173297\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "multimodal_tensor = torch.from_numpy(multimodal_all).float().to(device)\n",
    "label_tensor = torch.tensor(multimodal_idx).to(device)\n",
    "train_dataset = TensorDataset(multimodal_tensor, label_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "autoencoder = Autoencoder(encoding_dim=75).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "all_bottlenecks = []\n",
    "ys = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_data, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = autoencoder(batch_data)  # Access the data from the DataLoader\n",
    "        loss = criterion(outputs, batch_data)  # Compare with the input data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Append the bottleneck embeddings to the list\n",
    "        if epoch == num_epochs - 1:\n",
    "            all_bottlenecks.append(bottleneck)\n",
    "            ys.append(y)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}')\n",
    "    \n",
    "torch.save(autoencoder.state_dict(), 'models/feature_selection/multimodal_autoencoder_dim75.pth')\n",
    "all_bottlenecks_combined = torch.cat(all_bottlenecks, dim=0)\n",
    "ys = torch.cat(ys, dim=0)\n",
    "\n",
    "cluster_idx = []\n",
    "subject_label = []\n",
    "for y in ys:\n",
    "    cluster_idx.append(int(str(y.item())[:-4]+str(0)))\n",
    "    subject_label.append((int(str(y.item())[:-3])))\n",
    "    \n",
    "embeddings = all_bottlenecks_combined.cpu()\n",
    "embeddings_np = embeddings.detach().numpy()\n",
    "\n",
    "multimodal_df = pd.DataFrame(data=embeddings_np, columns=[f\"dim_{i+1}\" for i in range(embeddings_np.shape[1])])\n",
    "multimodal_df['idx'] = ys.cpu()\n",
    "multimodal_df['cluster_idx'] = cluster_idx\n",
    "multimodal_df['subject_idx'] = subject_label\n",
    "multimodal_df['t'] = multimodal_df['idx'].apply(lambda x: str(x)[-3:])\n",
    "\n",
    "multimodal_df = multimodal_df.sort_values(by=['subject_idx', 't'])\n",
    "multimodal_df = multimodal_df.reset_index(drop=True)\n",
    "multimodal_df.to_csv('output/feature_selection/multimodal_embeddings_dim75.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
